{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOB5a7DCbdgbvoMJSW97NFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/workspace/blob/main/ASR02/WER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WER calculation at the word level"
      ],
      "metadata": {
        "id": "Ib5GVfpP-gq6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkY471XJ-e3P"
      },
      "outputs": [],
      "source": [
        "#@markdown + Install and import libraries\n",
        "%%capture\n",
        "!pip install Levenshtein\n",
        "import Levenshtein as lev\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe to read"
      ],
      "metadata": {
        "id": "mKYVaNDYIe62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/MK316/workspace/main/ASR01/data/rainbow_bysentence.csv\"\n",
        "urlH = \"https://raw.githubusercontent.com/MK316/workspace/main/ASR01/results/HE_result_0519.csv\"\n",
        "urlE = \"https://raw.githubusercontent.com/MK316/workspace/main/ASR01/results/SETR_result.csv\"\n",
        "urlK = \"https://raw.githubusercontent.com/MK316/workspace/main/ASR01/results/SKTR_result.csv\"\n",
        "df = pd.read_csv(url)\n",
        "dfH = pd.read_csv(urlH)\n",
        "dfE = pd.read_csv(urlE)\n",
        "dfK = pd.read_csv(urlK)\n",
        "dfE.head()"
      ],
      "metadata": {
        "id": "Oa6OJB_GIhph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown + Calculate WER and WER_lev and add columns to df\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import Levenshtein as lev\n",
        "#@markdown + Column names 'Original' and 'Recognized' for comparison\n",
        "def calculate_wer_word_level(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Dynamic Time Warping algorithm at word level.\n",
        "    \"\"\"\n",
        "\n",
        "    # splitting the sentences into words\n",
        "    s1_words = s1.split()\n",
        "    s2_words = s2.split()\n",
        "\n",
        "    # preparing the matrix for the Dynamic Time Warping algorithm\n",
        "    dtw_matrix = np.zeros((len(s1_words)+1, len(s2_words)+1))\n",
        "    for i in range(len(s1_words)+1):\n",
        "        for j in range(len(s2_words)+1):\n",
        "            if i == 0:\n",
        "                dtw_matrix[0][j] = j\n",
        "            elif j == 0:\n",
        "                dtw_matrix[i][0] = i\n",
        "\n",
        "    # Dynamic Time Warping algorithm\n",
        "    for i in range(1, len(s1_words)+1):\n",
        "        for j in range(1, len(s2_words)+1):\n",
        "            cost = 0 if s1_words[i-1] == s2_words[j-1] else 1\n",
        "            dtw_matrix[i][j] = cost + min([dtw_matrix[i-1][j], dtw_matrix[i][j-1], dtw_matrix[i-1][j-1]])\n",
        "\n",
        "    wer = dtw_matrix[len(s1_words)][len(s2_words)] / len(s1_words)\n",
        "\n",
        "    return wer\n",
        "\n",
        "def calculate_wer_lev(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance at character level.\n",
        "    \"\"\"\n",
        "\n",
        "    # splitting the sentences into words\n",
        "    s1_words = s1.split()\n",
        "    s2_words = s2.split()\n",
        "\n",
        "    # calculating Levenshtein distance\n",
        "    edit_distance = lev.distance(' '.join(s1_words), ' '.join(s2_words))\n",
        "\n",
        "    # normalizing by the length of the original sentence (s1)\n",
        "    wer = edit_distance / len(s1_words)\n",
        "\n",
        "    return wer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C8NMeuBkD-er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and it has columns 'Sentence' and 'Recognized'\n",
        "wer_values_word_level = dfK.apply(lambda row: calculate_wer_word_level(row['Sentence'], row['Recognized']), axis=1)\n",
        "wer_values_lev = dfK.apply(lambda row: calculate_wer_lev(row['Sentence'], row['Recognized']), axis=1)\n",
        "\n",
        "# Adding WER values as new columns to the DataFrame\n",
        "dfK['WER'] = wer_values_word_level\n",
        "dfK['WER_lev'] = wer_values_lev\n",
        "\n",
        "# dfE\n",
        "wer_values_word_level = dfE.apply(lambda row: calculate_wer_word_level(row['Sentence'], row['Recognized']), axis=1)\n",
        "wer_values_lev = dfE.apply(lambda row: calculate_wer_lev(row['Sentence'], row['Recognized']), axis=1)\n",
        "\n",
        "# Adding WER values as new columns to the DataFrame\n",
        "dfE['WER'] = wer_values_word_level\n",
        "dfE['WER_lev'] = wer_values_lev\n",
        "\n",
        "# dfH\n",
        "\n",
        "wer_values_word_level = dfH.apply(lambda row: calculate_wer_word_level(row['Sentence'], row['Recognized']), axis=1)\n",
        "wer_values_lev = dfH.apply(lambda row: calculate_wer_lev(row['Sentence'], row['Recognized']), axis=1)\n",
        "\n",
        "# Adding WER values as new columns to the DataFrame\n",
        "dfH['WER'] = wer_values_word_level\n",
        "dfH['WER_lev'] = wer_values_lev"
      ],
      "metadata": {
        "id": "1XiU0noaEONL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfH1 = dfH[['SN','Sentence','Recognized','WER']]\n",
        "dfE1 = dfE[['SN','Sentence','Recognized','WER']]\n",
        "dfK1 = dfK[['SN','Sentence','Recognized','WER']]\n",
        "dfK1"
      ],
      "metadata": {
        "id": "GAtYaCG-eaqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average = dfK1['WER'].mean()\n",
        "std_dev = dfK1['WER'].std()\n",
        "\n",
        "print(\"K Average of WER: \", average)\n",
        "print(\"K Standard Deviation of WER: \", std_dev)\n",
        "\n",
        "average = dfE1['WER'].mean()\n",
        "std_dev = dfE1['WER'].std()\n",
        "\n",
        "print(\"E Average of WER: \", average)\n",
        "print(\"E Standard Deviation of WER: \", std_dev)\n",
        "\n",
        "average = dfH1['WER'].mean()\n",
        "std_dev = dfH1['WER'].std()\n",
        "\n",
        "print(\"H Average of WER: \", average)\n",
        "print(\"H Standard Deviation of WER: \", std_dev)"
      ],
      "metadata": {
        "id": "xcyeKuoCfAsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "range"
      ],
      "metadata": {
        "id": "i6UvPrJTp24z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_WERK = dfK1['WER'].min()\n",
        "max_WERK = dfK1['WER'].max()\n",
        "\n",
        "print(\"K Minimum WER: \", min_WERK)\n",
        "print(\"K Maximum WER: \", max_WERK)\n",
        "\n",
        "\n",
        "min_WERE = dfE1['WER'].min()\n",
        "max_WERE = dfE1['WER'].max()\n",
        "\n",
        "print(\"E Minimum WER: \", min_WERE)\n",
        "print(\"E Maximum WER: \", max_WERE)\n",
        "\n",
        "min_WERH = dfH1['WER'].min()\n",
        "max_WERH = dfH1['WER'].max()\n",
        "\n",
        "print(\"H Minimum WER: \", min_WERH)\n",
        "print(\"H Maximum WER: \", max_WERH)"
      ],
      "metadata": {
        "id": "942KRQIpp2Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perception sentence WER\n",
        "\n",
        "30 subjects * 2 conditions (pre vs. post) = 60 items\n",
        "\n",
        "File: [EPA_recog_all.csv](https://raw.githubusercontent.com/MK316/workspace/main/ASR02/results/EPA_recog_all.csv)\n",
        "\n",
        "File coded: [EPA_stimuli_coded.csv](https://raw.githubusercontent.com/MK316/workspace/main/ASR02/results/EPA_stimuli_coded.csv) May19 4pm"
      ],
      "metadata": {
        "id": "l0Ene9KOzewV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pFFEvsCl63Ai"
      },
      "outputs": [],
      "source": [
        "#@markdown + Install and import libraries\n",
        "%%capture\n",
        "!pip install Levenshtein\n",
        "import Levenshtein as lev\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/workspace/main/ASR02/results/EPA_stimuli_coded.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "0UIXzhEK0ui0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown + Calculate WER and WER_lev and add columns to df\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import Levenshtein as lev\n",
        "#@markdown + Column names 'Original' and 'Recognized' for comparison\n",
        "def calculate_wer_word_level(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Dynamic Time Warping algorithm at word level.\n",
        "    \"\"\"\n",
        "\n",
        "    # splitting the sentences into words\n",
        "    s1_words = s1.split()\n",
        "    s2_words = s2.split()\n",
        "\n",
        "    # preparing the matrix for the Dynamic Time Warping algorithm\n",
        "    dtw_matrix = np.zeros((len(s1_words)+1, len(s2_words)+1))\n",
        "    for i in range(len(s1_words)+1):\n",
        "        for j in range(len(s2_words)+1):\n",
        "            if i == 0:\n",
        "                dtw_matrix[0][j] = j\n",
        "            elif j == 0:\n",
        "                dtw_matrix[i][0] = i\n",
        "\n",
        "    # Dynamic Time Warping algorithm\n",
        "    for i in range(1, len(s1_words)+1):\n",
        "        for j in range(1, len(s2_words)+1):\n",
        "            cost = 0 if s1_words[i-1] == s2_words[j-1] else 1\n",
        "            dtw_matrix[i][j] = cost + min([dtw_matrix[i-1][j], dtw_matrix[i][j-1], dtw_matrix[i-1][j-1]])\n",
        "\n",
        "    wer = dtw_matrix[len(s1_words)][len(s2_words)] / len(s1_words)\n",
        "\n",
        "    return wer\n",
        "\n",
        "def calculate_wer_lev(s1, s2):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance at character level.\n",
        "    \"\"\"\n",
        "\n",
        "    # splitting the sentences into words\n",
        "    s1_words = s1.split()\n",
        "    s2_words = s2.split()\n",
        "\n",
        "    # calculating Levenshtein distance\n",
        "    edit_distance = lev.distance(' '.join(s1_words), ' '.join(s2_words))\n",
        "\n",
        "    # normalizing by the length of the original sentence (s1)\n",
        "    wer = edit_distance / len(s1_words)\n",
        "\n",
        "    return wer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iOnqDG5f6SWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame and it has columns 'Sentence' and 'Recognized'\n",
        "import numpy as np\n",
        "\n",
        "wer_values_word_level = df.apply(lambda row: calculate_wer_word_level(row['Sentence'], row['Recognized']), axis=1)\n",
        "wer_values_lev = df.apply(lambda row: calculate_wer_lev(row['Sentence'], row['Recognized']), axis=1)\n",
        "\n",
        "# Adding WER values as new columns to the DataFrame\n",
        "df['WER'] = wer_values_word_level\n",
        "df['WER_lev'] = wer_values_lev"
      ],
      "metadata": {
        "id": "BUDm7pYd6SIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df[['SN','Filename','Conditions','Subjects','Gender','Sentence','Recognized','WER','WER_lev']]\n",
        "df1.tail()"
      ],
      "metadata": {
        "id": "uEy4Poe86BA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1[['Subjects','Conditions','WER','WER_lev']]\n",
        "df2\n",
        "\n",
        "df2.to_csv('WER_total.csv', index=False)"
      ],
      "metadata": {
        "id": "SdpYudk-hy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.describe(include='all')"
      ],
      "metadata": {
        "id": "np5YzXAD7EMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.groupby('Conditions')['WER'].describe()\n",
        "df.groupby('Conditions')['WER'].describe()"
      ],
      "metadata": {
        "id": "-KcJY4QA9oF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "CpVAn09W-8kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Paired t-test to see Pre vs. Post difference"
      ],
      "metadata": {
        "id": "eCibIHdA-_6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# Separate the data into pre and post groups\n",
        "pre = df[df['Conditions'] == 'PRE']['WER_lev']\n",
        "post = df[df['Conditions'] == 'POST']['WER_lev']\n",
        "\n",
        "# Run the paired t-test\n",
        "t_stat, p_val = stats.ttest_rel(pre, post)\n",
        "\n",
        "print('T-statistic:', t_stat)\n",
        "print('P-value:', p_val)\n"
      ],
      "metadata": {
        "id": "QX8Z9pY9_D2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No statistical difference"
      ],
      "metadata": {
        "id": "b-yFkcbO_kZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.boxplot(x='Conditions', y='WER_lev', data=df)\n",
        "\n",
        "plt.ylim(0, 3)\n",
        "plt.title('Boxplot of WER by Condition')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MKj7htn4_zdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot the data\n",
        "df_pivot = df.pivot(index='Subjects', columns='Conditions', values='WER_lev')\n",
        "\n",
        "# Plot\n",
        "sns.scatterplot(x='PRE', y='POST', data=df_pivot)\n",
        "\n",
        "plt.title('Scatterplot of WER: Pre vs. Post')\n",
        "plt.ylim(0, 3)\n",
        "plt.xlim(0, 3)\n",
        "plt.xlabel('WER Pre')\n",
        "plt.ylabel('WER Post')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "HlcoC8F7AW60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Loop over each unique subject\n",
        "for subject in df['Subjects'].unique():\n",
        "    df_subject = df[df['Subjects'] == subject]  # Filter the data for this subject\n",
        "    ax.plot(df_subject['Conditions'], df_subject['WER'], marker='o', linestyle='-')\n",
        "\n",
        "plt.title('Change in WER from Pre to Post by Subject')\n",
        "plt.xlabel('Condition')\n",
        "plt.ylabel('WER')\n",
        "plt.xticks(['Pre', 'Post'])  # Ensure x-axis labels are in the correct order\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LS3H_3afCcc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Define mapping of conditions to numbers\n",
        "conditions_map = {'PRE': 0, 'POST': 1}\n",
        "\n",
        "# Loop over each unique subject\n",
        "for subject in df['Subjects'].unique():\n",
        "    df_subject = df[df['Subjects'] == subject]  # Filter the data for this subject\n",
        "    ax.plot(df_subject['Conditions'].map(conditions_map), df_subject['WER'], marker='o', linestyle='-')\n",
        "\n",
        "plt.title('Change in WER from Pre to Post by Subject')\n",
        "plt.xlabel('Condition')\n",
        "plt.ylabel('WER')\n",
        "plt.xticks(list(conditions_map.values()), list(conditions_map.keys()))  # Set x-axis tick labels to 'Pre' and 'Post'\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0uLa3sICDhEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-way ANOVA: no difference"
      ],
      "metadata": {
        "id": "9AUuJGUZEeGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Fit the model\n",
        "model = ols('WER_lev ~ C(Conditions) + C(Gender) + C(Conditions):C(Gender)', data=df).fit()\n",
        "\n",
        "# Perform the ANOVA\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n"
      ],
      "metadata": {
        "id": "sNeE7Ap3EgAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group subjects by SAME, POS, NEG by calculating WER difference in PRE and POST conditions"
      ],
      "metadata": {
        "id": "n9LLRQQdGqCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot the DataFrame to compute the difference between 'Pre' and 'Post'\n",
        "df_pivot = df.pivot(index='Subjects', columns='Conditions', values='WER')\n",
        "df_pivot['Difference'] = df_pivot['PRE'] - df_pivot['POST']\n",
        "df_pivot['Stimuli'] = df_pivot.index\n",
        "\n",
        "# Create a new column to categorize the subjects\n",
        "df_pivot['Category'] = 'No Difference'\n",
        "df_pivot.loc[df_pivot['Difference'] > 0, 'Category'] = 'Positive Change'\n",
        "df_pivot.loc[df_pivot['Difference'] < 0, 'Category'] = 'Negative Change'\n",
        "\n",
        "# Save the DataFrame to a .csv file\n",
        "df_pivot.to_csv('WER_difference.csv')\n",
        "\n",
        "\n",
        "print(df_pivot)\n"
      ],
      "metadata": {
        "id": "R-lz6q9bGxRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of occurrences of each category\n",
        "category_counts = df_pivot['Category'].value_counts()\n",
        "\n",
        "print(category_counts)\n"
      ],
      "metadata": {
        "id": "3OkbAmRaHRaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"the programs about detectives and hospitals are my favorites\"\n",
        "words = sentence.split()\n",
        "number_of_words = len(words)\n",
        "print(number_of_words)\n"
      ],
      "metadata": {
        "id": "QTe9pGBIIppg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to map categories to colors\n",
        "color_dict = {'Positive Change': '#87CEFA', 'No Difference': 'gray', 'Negative Change': 'yellow'}\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.barplot(x='Category', y='Count', data=category_counts_df, palette=color_dict)\n",
        "plt.title('Count of Each Category')\n",
        "plt.ylim(0, 15)\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Add the text\n",
        "plt.text(0.95, 0.95, 'N = 30', ha='right', va='top', transform=plt.gca().transAxes)\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('category_counts.png', dpi=800, bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KUVDMFGbLGqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pivot the DataFrame to get the WER values in the POST condition and the PRE condition\n",
        "df_pivot = df.pivot(index='Subjects', columns='Conditions', values='WER')\n",
        "\n",
        "# Calculate the difference by subtracting the PRE WER from the POST WER\n",
        "difference = df_pivot['POST'] - df_pivot['PRE']\n",
        "\n",
        "# Set the x-axis labels\n",
        "x_labels = df_pivot.index\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=x_labels, y=difference, palette=['red' if d < 0 else 'blue' for d in difference])\n",
        "plt.title('WER Difference: POST over PRE')\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('WER Difference')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a4HYuOHeTxgn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}