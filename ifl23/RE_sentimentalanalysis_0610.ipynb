{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOn61K1myeF5DGeAofTVs6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/workspace/blob/main/ifl23/RE_sentimentalanalysis_0610.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud with Korean text"
      ],
      "metadata": {
        "id": "4MhPM0nRuTyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[text](https://raw.githubusercontent.com/MK316/workspace/main/ifl23/data/reflection.csv) in csv file"
      ],
      "metadata": {
        "id": "Cblfh2zzvndN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "sHXU93NjwbrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file from GitHub\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/MK316/workspace/main/ifl23/data/reflection.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "cHvIZMHG4fUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPyzfEAByM6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppn-NfO6uSti"
      },
      "outputs": [],
      "source": [
        "# Combine all rows in the 'reflection' column into one string\n",
        "# text = ' '.join(df['Reflection'])\n",
        "text = ' '.join(df['RE'].dropna().astype(str))\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# You'll need to have a list of Korean stop words available\n",
        "stop_words = ['stop', 'word', 'list']  # replace this with your actual list of Korean stop words\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "# Create a WordCloud\n",
        "wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(tokens))\n",
        "\n",
        "# wordcloud = WordCloud(\n",
        "#     font_path='/content/your_font_file.ttf',  # replace with the name of your uploaded font file\n",
        "#     width = 1000, \n",
        "#     height = 500\n",
        "# ).generate(' '.join(tokens))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "C3-TuBg141Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment analysis\n",
        "# Please note that SentimentIntensityAnalyzer is designed for English text, so it may not give accurate results for Korean text\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "print(sentiment_scores)"
      ],
      "metadata": {
        "id": "X8nkUtGuxFUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result description**: The sentiment analysis of the text reveals a predominantly neutral tone, with 81.1% of the content classified as such. Positive sentiment constitutes 14.7% of the text, while negative sentiment is minimal, accounting for only 4.2%. Most notably, the compound score, a metric that encapsulates the overall sentiment of the text, is extremely high at 0.9999 (on a scale from -1 to 1). This suggests that despite the considerable proportion of neutral content, the text as a whole leans heavily towards a positive sentiment.\n",
        "\n",
        "+ 'neg': This is the Negative sentiment score. It represents the proportion of the text that is classified as negative. In your case, 4.2% of the text is classified as negative.\n",
        "\n",
        "+ 'neu': This is the Neutral sentiment score. It represents the proportion of the text that is classified as neutral. In your case, 81.1% of the text is classified as neutral.\n",
        "\n",
        "+ 'pos': This is the Positive sentiment score. It represents the proportion of the text that is classified as positive. In your case, 14.7% of the text is classified as positive.\n",
        "\n",
        "+ 'compound': This is the Compound score. It is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive). This score is a good indicator of the overall sentiment of the text. Positive values indicate positive sentiment, negative values indicate negative sentiment, and values close to zero indicate neutral sentiment. In your case, the compound score is 0.9999, which is very close to 1, indicating a very strong positive sentiment overall.\n",
        "+ The compound score in the NLTK's SentimentIntensityAnalyzer is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive).\n",
        "\n",
        "The calculation of the compound score is a bit complex. It uses the valence scores of each word in the text, which are determined by the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\n",
        "\n",
        "Here is a simplified explanation of how it works:\n",
        "\n",
        "Each word in the text is assigned a valence score from the VADER lexicon. The valence score of a word is a measure of its emotional intensity ranging from -4 to +4. For example, the word \"love\" has a valence score of 3.2.\n",
        "\n",
        "These scores are adjusted based on the context of the word in the text. For example, if a word is in ALL CAPS, its valence score is increased. If a word is preceded by a negation word (like \"not\" or \"never\"), its valence score is reversed.\n",
        "\n",
        "The adjusted scores are then summed up and normalized to be between -1 and +1 to get the compound score.\n",
        "\n",
        "The exact calculation involves some additional steps and is beyond the scope of this explanation. If you're interested in the details, you can check out the source code of the SentimentIntensityAnalyzer or the original paper on VADER.\n",
        "\n",
        "Please note that the compound score is a good indicator of the overall sentiment of the text, but it may not always accurately reflect the sentiment of individual sentences or phrases within the text."
      ],
      "metadata": {
        "id": "QCudxDbF5x5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sentiment analysis\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sentiment_scores = sia.polarity_scores(text)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(sentiment_scores.keys(), sentiment_scores.values())\n",
        "plt.title('Sentiment Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WybKmBPZ5How"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(sentiment_scores.values(), labels=sentiment_scores.keys(), autopct='%1.1f%%')\n",
        "plt.title('Sentiment Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kfAvuAbV6CxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(list(sentiment_scores.keys()), list(sentiment_scores.values()))\n",
        "plt.title('Sentiment Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "16zhBb986JnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential colormaps: These are good for data that ranges from low to high. Examples include 'Blues', 'BuGn' (blue to green), 'OrRd' (orange to red), and 'Greys'.\n",
        "\n",
        "Diverging colormaps: These are good for data that has a meaningful zero point or a specific value of interest. Examples include 'coolwarm', 'bwr' (blue, white, red), 'seismic', and 'RdBu' (red to blue).\n",
        "\n",
        "Qualitative colormaps: These are good for data that has no inherent ordering, such as categories or labels. Examples include 'Pastel1', 'Set1', 'tab10', and 'tab20'.\n",
        "\n",
        "Miscellaneous colormaps: These include 'flag', 'prism', 'ocean', 'gist_earth', 'terrain', and 'nipy_spectral'."
      ],
      "metadata": {
        "id": "9Qyi0dGL6rFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the scores to a DataFrame\n",
        "df_scores = pd.DataFrame([sentiment_scores])\n",
        "\n",
        "# Create a heatmap\n",
        "sns.heatmap(df_scores, annot=True, cmap='RdBu')\n",
        "plt.title('Sentiment Scores')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3PXH1IEi6Lbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword analysis"
      ],
      "metadata": {
        "id": "Pi3-ptVj8eVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.text import Text\n",
        "\n",
        "# Let's say you want to extract the context of the word \"example\" in the 'reflection' column of your DataFrame\n",
        "word = 'coding'\n",
        "\n",
        "# Combine all rows in the 'reflection' column into one string\n",
        "text = ' '.join(df['RE'].dropna().astype(str))\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Create a Text object\n",
        "text_obj = Text(tokens)\n",
        "\n",
        "# Create a concordance (KWIC) for the word\n",
        "text_obj.concordance(word)\n"
      ],
      "metadata": {
        "id": "u-eMmUKQ8f64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, row in df.iterrows():\n",
        "    text = ' '.join(df['RE'].dropna().astype(str))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    text_obj = Text(tokens)\n",
        "    text_obj.concordance(word)\n"
      ],
      "metadata": {
        "id": "KfP7lTem8zar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.text import Text\n",
        "\n",
        "def limited_concordance(txt_obj, keyword, width=79, lines=25):\n",
        "    \"\"\"\n",
        "    Print a limited concordance for `keyword` in `txt_obj`.\n",
        "\n",
        "    :param txt_obj: The Text object to search.\n",
        "    :param keyword: The word to find.\n",
        "    :param width: The width of each line (default is 79, same as nltk.Text.concordance).\n",
        "    :param lines: The maximum number of lines to print (default is 25, same as nltk.Text.concordance).\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a concordance index\n",
        "    concordance_index = nltk.text.ConcordanceIndex(txt_obj.tokens)\n",
        "\n",
        "    # Find the offsets for the keyword\n",
        "    offsets = concordance_index.offsets(keyword)\n",
        "\n",
        "    # Only keep the first `lines` offsets\n",
        "    offsets = offsets[:lines]\n",
        "\n",
        "    # Print the concordance\n",
        "    for offset in offsets:\n",
        "        left = ' '.join(txt_obj.tokens[offset-width//2 : offset])\n",
        "        right = ' '.join(txt_obj.tokens[offset+1 : offset+width//2+1])\n",
        "        print(f'{left[-width//2:]:{width//2}} {txt_obj.tokens[offset]} {right[:width//2]:{width//2}}')\n",
        "\n",
        "# Combine all rows in the 'reflection' column into one string\n",
        "text = ' '.join(df['RE'].dropna().astype(str))\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Create a Text object\n",
        "text_obj = Text(tokens)\n",
        "\n",
        "# Create a limited concordance for the word \"example\"\n",
        "limited_concordance(text_obj, 'coding', lines=10)"
      ],
      "metadata": {
        "id": "NSfDA6S09di1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}